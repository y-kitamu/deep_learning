{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kitamura/.local/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:44: UserWarning: You are currently using a nightly version of TensorFlow (2.2.0-dev20200403). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from data_utils import CIFAR10Data\n",
    "from resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   1728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36864       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36864       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           re_lu[0][0]                      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 32, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36864       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36864       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           re_lu_2[0][0]                    \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73728       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  8192        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  147456      re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 128)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16, 16, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147456      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147456      re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           re_lu_6[0][0]                    \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 16, 16, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    294912      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 8, 8, 256)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    32768       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    589824      re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    589824      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    589824      re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 256)    0           re_lu_10[0][0]                   \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 8, 8, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 512)    1179648     re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 512)    131072      re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 512)    2359296     re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 512)    2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 512)    2359296     re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 512)    2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 512)    2359296     re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 512)    0           re_lu_14[0][0]                   \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 4, 4, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 512)    0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           5130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,183,562\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 5e-4\n",
    "lr = 1e-1\n",
    "num_classes = 10\n",
    "\n",
    "# model = ResNet50(\n",
    "#     weights=None,\n",
    "#     input_shape=x_train.shape[1:],\n",
    "#     classes=num_classes,\n",
    "# )\n",
    "model = ResNet18(\n",
    "    classes=num_classes,\n",
    "    input_shape=(32, 32, 3),\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(\n",
    "    learning_rate=lr,\n",
    "    momentum=0.9,\n",
    "    nesterov=False\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kitamura/work/DeepLearning/Cifar10/solver.py:55: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "new lf : 0.1\n",
      "Epoch 1/200\n",
      "313/313 [==============================] - ETA: 0s - loss: 4.3266 - accuracy: 0.2821\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.29880, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 3.43558, saving model to ./model/20201103_213554/best_val_loss.hdf5\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 4.3266 - accuracy: 0.2821 - val_loss: 3.4356 - val_accuracy: 0.2988 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 2/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 2.7687 - accuracy: 0.4293\n",
      "Epoch 00002: val_accuracy improved from 0.29880 to 0.40660, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 2.7674 - accuracy: 0.4293 - val_loss: 2.5829 - val_accuracy: 0.4066 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 3/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 2.0323 - accuracy: 0.5262\n",
      "Epoch 00003: val_accuracy improved from 0.40660 to 0.58010, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 2.0307 - accuracy: 0.5264 - val_loss: 1.7490 - val_accuracy: 0.5801 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 4/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.6069 - accuracy: 0.5980\n",
      "Epoch 00004: val_accuracy improved from 0.58010 to 0.61720, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.6064 - accuracy: 0.5979 - val_loss: 1.4847 - val_accuracy: 0.6172 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 5/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.3670 - accuracy: 0.6486\n",
      "Epoch 00005: val_accuracy did not improve from 0.61720\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.3658 - accuracy: 0.6488 - val_loss: 1.4755 - val_accuracy: 0.6120 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 6/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.2256 - accuracy: 0.6866\n",
      "Epoch 00006: val_accuracy improved from 0.61720 to 0.69170, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.2255 - accuracy: 0.6866 - val_loss: 1.1963 - val_accuracy: 0.6917 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 7/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.1149 - accuracy: 0.7187\n",
      "Epoch 00007: val_accuracy did not improve from 0.69170\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.1147 - accuracy: 0.7187 - val_loss: 1.5756 - val_accuracy: 0.6228 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 8/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.0502 - accuracy: 0.7479\n",
      "Epoch 00008: val_accuracy improved from 0.69170 to 0.69560, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.0506 - accuracy: 0.7478 - val_loss: 1.1850 - val_accuracy: 0.6956 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 9/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9858 - accuracy: 0.7719\n",
      "Epoch 00009: val_accuracy did not improve from 0.69560\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.9860 - accuracy: 0.7719 - val_loss: 1.2327 - val_accuracy: 0.6860 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 10/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9632 - accuracy: 0.7836\n",
      "Epoch 00010: val_accuracy improved from 0.69560 to 0.73410, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9634 - accuracy: 0.7836 - val_loss: 1.1051 - val_accuracy: 0.7341 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 11/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9291 - accuracy: 0.7990\n",
      "Epoch 00011: val_accuracy improved from 0.73410 to 0.74270, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9290 - accuracy: 0.7989 - val_loss: 1.0952 - val_accuracy: 0.7427 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 12/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9184 - accuracy: 0.8065\n",
      "Epoch 00012: val_accuracy improved from 0.74270 to 0.74540, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9186 - accuracy: 0.8063 - val_loss: 1.1670 - val_accuracy: 0.7454 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 13/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.9163 - accuracy: 0.8097\n",
      "Epoch 00013: val_accuracy improved from 0.74540 to 0.74550, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9163 - accuracy: 0.8098 - val_loss: 1.1049 - val_accuracy: 0.7455 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 14/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8922 - accuracy: 0.8190\n",
      "Epoch 00014: val_accuracy improved from 0.74550 to 0.78850, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8929 - accuracy: 0.8189 - val_loss: 0.9811 - val_accuracy: 0.7885 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 15/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.8259\n",
      "Epoch 00015: val_accuracy did not improve from 0.78850\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8812 - accuracy: 0.8259 - val_loss: 1.1007 - val_accuracy: 0.7543 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 16/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8688 - accuracy: 0.8293\n",
      "Epoch 00016: val_accuracy did not improve from 0.78850\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8687 - accuracy: 0.8293 - val_loss: 1.1654 - val_accuracy: 0.7459 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 17/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8608 - accuracy: 0.8337\n",
      "Epoch 00017: val_accuracy did not improve from 0.78850\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8609 - accuracy: 0.8337 - val_loss: 1.1729 - val_accuracy: 0.7431 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 18/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8527 - accuracy: 0.8393\n",
      "Epoch 00018: val_accuracy improved from 0.78850 to 0.81550, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8539 - accuracy: 0.8391 - val_loss: 0.9309 - val_accuracy: 0.8155 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 19/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8441 - accuracy: 0.8412\n",
      "Epoch 00019: val_accuracy did not improve from 0.81550\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8444 - accuracy: 0.8412 - val_loss: 1.2964 - val_accuracy: 0.7214 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 20/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8469 - accuracy: 0.8437\n",
      "Epoch 00020: val_accuracy did not improve from 0.81550\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8469 - accuracy: 0.8436 - val_loss: 0.9477 - val_accuracy: 0.8129 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 21/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8344 - accuracy: 0.8483\n",
      "Epoch 00021: val_accuracy did not improve from 0.81550\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8342 - accuracy: 0.8483 - val_loss: 1.2174 - val_accuracy: 0.7432 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 22/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8421 - accuracy: 0.8460\n",
      "Epoch 00022: val_accuracy improved from 0.81550 to 0.82080, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8427 - accuracy: 0.8460 - val_loss: 0.9467 - val_accuracy: 0.8208 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 23/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8331 - accuracy: 0.8526\n",
      "Epoch 00023: val_accuracy did not improve from 0.82080\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8331 - accuracy: 0.8526 - val_loss: 1.0367 - val_accuracy: 0.7887 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 24/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8250 - accuracy: 0.8563\n",
      "Epoch 00024: val_accuracy did not improve from 0.82080\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8248 - accuracy: 0.8563 - val_loss: 1.0667 - val_accuracy: 0.7726 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 25/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8281 - accuracy: 0.8550\n",
      "Epoch 00025: val_accuracy did not improve from 0.82080\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8280 - accuracy: 0.8550 - val_loss: 1.0105 - val_accuracy: 0.8030 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 26/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8174 - accuracy: 0.8595\n",
      "Epoch 00026: val_accuracy did not improve from 0.82080\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8181 - accuracy: 0.8594 - val_loss: 1.1050 - val_accuracy: 0.7842 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 27/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8169 - accuracy: 0.8617\n",
      "Epoch 00027: val_accuracy did not improve from 0.82080\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8171 - accuracy: 0.8616 - val_loss: 1.2087 - val_accuracy: 0.7451 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 28/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8250 - accuracy: 0.8595\n",
      "Epoch 00028: val_accuracy improved from 0.82080 to 0.82480, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8249 - accuracy: 0.8596 - val_loss: 0.9617 - val_accuracy: 0.8248 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 29/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.8628\n",
      "Epoch 00029: val_accuracy did not improve from 0.82480\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8186 - accuracy: 0.8628 - val_loss: 1.1891 - val_accuracy: 0.7470 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 30/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.8646\n",
      "Epoch 00030: val_accuracy did not improve from 0.82480\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8128 - accuracy: 0.8646 - val_loss: 1.0289 - val_accuracy: 0.8020 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 31/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8125 - accuracy: 0.8661\n",
      "Epoch 00031: val_accuracy did not improve from 0.82480\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8131 - accuracy: 0.8661 - val_loss: 1.1090 - val_accuracy: 0.7762 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 32/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8084 - accuracy: 0.8688\n",
      "Epoch 00032: val_accuracy did not improve from 0.82480\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8080 - accuracy: 0.8689 - val_loss: 0.9969 - val_accuracy: 0.8128 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 33/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.8686\n",
      "Epoch 00033: val_accuracy improved from 0.82480 to 0.82990, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.8127 - accuracy: 0.8686 - val_loss: 0.9197 - val_accuracy: 0.8299 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 34/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8074 - accuracy: 0.8697\n",
      "Epoch 00034: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8075 - accuracy: 0.8698 - val_loss: 1.0671 - val_accuracy: 0.7943 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 35/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8116 - accuracy: 0.8681\n",
      "Epoch 00035: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8116 - accuracy: 0.8680 - val_loss: 1.1200 - val_accuracy: 0.7696 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 36/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.8721\n",
      "Epoch 00036: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8015 - accuracy: 0.8721 - val_loss: 1.1676 - val_accuracy: 0.7592 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 37/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8069 - accuracy: 0.8716\n",
      "Epoch 00037: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8074 - accuracy: 0.8716 - val_loss: 1.1298 - val_accuracy: 0.7787 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 38/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8023 - accuracy: 0.8750\n",
      "Epoch 00038: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8025 - accuracy: 0.8750 - val_loss: 1.0188 - val_accuracy: 0.8000 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 39/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8073 - accuracy: 0.8719\n",
      "Epoch 00039: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8075 - accuracy: 0.8718 - val_loss: 1.2323 - val_accuracy: 0.7459 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 40/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7953 - accuracy: 0.8766\n",
      "Epoch 00040: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7953 - accuracy: 0.8766 - val_loss: 1.2372 - val_accuracy: 0.7537 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 41/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.8754\n",
      "Epoch 00041: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8017 - accuracy: 0.8755 - val_loss: 1.0714 - val_accuracy: 0.7945 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 42/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8002 - accuracy: 0.8749\n",
      "Epoch 00042: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7999 - accuracy: 0.8750 - val_loss: 1.0268 - val_accuracy: 0.7984 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 43/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7998 - accuracy: 0.8770\n",
      "Epoch 00043: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8000 - accuracy: 0.8770 - val_loss: 0.9854 - val_accuracy: 0.8217 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 44/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8053 - accuracy: 0.8753\n",
      "Epoch 00044: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8055 - accuracy: 0.8752 - val_loss: 1.0655 - val_accuracy: 0.7952 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 45/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7947 - accuracy: 0.8805\n",
      "Epoch 00045: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7951 - accuracy: 0.8805 - val_loss: 1.0528 - val_accuracy: 0.8062 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 46/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8004 - accuracy: 0.8775\n",
      "Epoch 00046: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8009 - accuracy: 0.8774 - val_loss: 1.0504 - val_accuracy: 0.7998 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 47/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8004 - accuracy: 0.8797\n",
      "Epoch 00047: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8000 - accuracy: 0.8796 - val_loss: 1.0369 - val_accuracy: 0.8007 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 48/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7992 - accuracy: 0.8799\n",
      "Epoch 00048: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7993 - accuracy: 0.8799 - val_loss: 1.0569 - val_accuracy: 0.7998 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 49/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7944 - accuracy: 0.8819\n",
      "Epoch 00049: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7947 - accuracy: 0.8818 - val_loss: 1.0172 - val_accuracy: 0.8116 - lr: 0.1000\n",
      "new lf : 0.1\n",
      "Epoch 50/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.8798\n",
      "Epoch 00050: val_accuracy did not improve from 0.82990\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8008 - accuracy: 0.8798 - val_loss: 1.0478 - val_accuracy: 0.8035 - lr: 0.1000\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 51/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.9163\n",
      "Epoch 00051: val_accuracy improved from 0.82990 to 0.90980, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.6936 - accuracy: 0.9164 - val_loss: 0.7075 - val_accuracy: 0.9098 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 52/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.9438\n",
      "Epoch 00052: val_accuracy improved from 0.90980 to 0.91570, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5926 - accuracy: 0.9438 - val_loss: 0.6624 - val_accuracy: 0.9157 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 53/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.9529\n",
      "Epoch 00053: val_accuracy improved from 0.91570 to 0.91820, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5405 - accuracy: 0.9530 - val_loss: 0.6336 - val_accuracy: 0.9182 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 54/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.9581\n",
      "Epoch 00054: val_accuracy improved from 0.91820 to 0.92110, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5027 - accuracy: 0.9582 - val_loss: 0.6073 - val_accuracy: 0.9211 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 55/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.9636\n",
      "Epoch 00055: val_accuracy improved from 0.92110 to 0.92370, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.4667 - accuracy: 0.9637 - val_loss: 0.5846 - val_accuracy: 0.9237 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 56/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.9674\n",
      "Epoch 00056: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.4352 - accuracy: 0.9673 - val_loss: 0.5706 - val_accuracy: 0.9210 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 57/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.9709\n",
      "Epoch 00057: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.4065 - accuracy: 0.9708 - val_loss: 0.5626 - val_accuracy: 0.9188 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 58/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.9742\n",
      "Epoch 00058: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.3811 - accuracy: 0.9742 - val_loss: 0.5981 - val_accuracy: 0.9103 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 59/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.9764\n",
      "Epoch 00059: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3583 - accuracy: 0.9764 - val_loss: 0.5509 - val_accuracy: 0.9212 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 60/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.9778\n",
      "Epoch 00060: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3394 - accuracy: 0.9778 - val_loss: 0.5446 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 61/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.9798\n",
      "Epoch 00061: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3221 - accuracy: 0.9797 - val_loss: 0.5123 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 62/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.9812\n",
      "Epoch 00062: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3057 - accuracy: 0.9812 - val_loss: 0.5516 - val_accuracy: 0.9126 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 63/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.9802\n",
      "Epoch 00063: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2966 - accuracy: 0.9803 - val_loss: 0.5187 - val_accuracy: 0.9155 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 64/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.9806\n",
      "Epoch 00064: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2853 - accuracy: 0.9806 - val_loss: 0.5125 - val_accuracy: 0.9182 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 65/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9828\n",
      "Epoch 00065: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2700 - accuracy: 0.9829 - val_loss: 0.5172 - val_accuracy: 0.9142 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 66/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9814\n",
      "Epoch 00066: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2664 - accuracy: 0.9814 - val_loss: 0.5215 - val_accuracy: 0.9131 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 67/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2586 - accuracy: 0.9815\n",
      "Epoch 00067: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2590 - accuracy: 0.9815 - val_loss: 0.5754 - val_accuracy: 0.8970 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 68/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9821\n",
      "Epoch 00068: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2506 - accuracy: 0.9821 - val_loss: 0.5112 - val_accuracy: 0.9164 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 69/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9816\n",
      "Epoch 00069: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2433 - accuracy: 0.9816 - val_loss: 0.5323 - val_accuracy: 0.9058 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 70/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9809\n",
      "Epoch 00070: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2426 - accuracy: 0.9809 - val_loss: 0.5389 - val_accuracy: 0.9044 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 71/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9813\n",
      "Epoch 00071: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2377 - accuracy: 0.9813 - val_loss: 0.5131 - val_accuracy: 0.9105 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 72/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2308 - accuracy: 0.9826\n",
      "Epoch 00072: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2308 - accuracy: 0.9826 - val_loss: 0.4768 - val_accuracy: 0.9169 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 73/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9793\n",
      "Epoch 00073: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2350 - accuracy: 0.9793 - val_loss: 0.5293 - val_accuracy: 0.9072 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 74/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.9798\n",
      "Epoch 00074: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2325 - accuracy: 0.9798 - val_loss: 0.4983 - val_accuracy: 0.9092 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 75/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9808\n",
      "Epoch 00075: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2276 - accuracy: 0.9807 - val_loss: 0.5281 - val_accuracy: 0.9043 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 76/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9814\n",
      "Epoch 00076: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2244 - accuracy: 0.9814 - val_loss: 0.5262 - val_accuracy: 0.9046 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 77/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9788\n",
      "Epoch 00077: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2273 - accuracy: 0.9789 - val_loss: 0.5200 - val_accuracy: 0.9028 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 78/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9789\n",
      "Epoch 00078: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2255 - accuracy: 0.9789 - val_loss: 0.5127 - val_accuracy: 0.9086 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 79/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9807\n",
      "Epoch 00079: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2190 - accuracy: 0.9807 - val_loss: 0.5161 - val_accuracy: 0.9050 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 80/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9806\n",
      "Epoch 00080: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2204 - accuracy: 0.9807 - val_loss: 0.5913 - val_accuracy: 0.8952 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 81/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9782\n",
      "Epoch 00081: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2252 - accuracy: 0.9782 - val_loss: 0.5588 - val_accuracy: 0.8965 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 82/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9794\n",
      "Epoch 00082: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2218 - accuracy: 0.9794 - val_loss: 0.5332 - val_accuracy: 0.9055 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 83/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9802\n",
      "Epoch 00083: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2185 - accuracy: 0.9802 - val_loss: 0.5127 - val_accuracy: 0.9083 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 84/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9799\n",
      "Epoch 00084: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2195 - accuracy: 0.9800 - val_loss: 0.5093 - val_accuracy: 0.9083 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 85/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9787\n",
      "Epoch 00085: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2217 - accuracy: 0.9786 - val_loss: 0.4872 - val_accuracy: 0.9088 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 86/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9808\n",
      "Epoch 00086: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2186 - accuracy: 0.9808 - val_loss: 0.4974 - val_accuracy: 0.9102 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 87/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9810\n",
      "Epoch 00087: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2158 - accuracy: 0.9810 - val_loss: 0.4945 - val_accuracy: 0.9092 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 88/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9801\n",
      "Epoch 00088: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2204 - accuracy: 0.9800 - val_loss: 0.5303 - val_accuracy: 0.9059 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 89/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9806\n",
      "Epoch 00089: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2182 - accuracy: 0.9807 - val_loss: 0.5440 - val_accuracy: 0.8967 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 90/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9817\n",
      "Epoch 00090: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2156 - accuracy: 0.9817 - val_loss: 0.5575 - val_accuracy: 0.8947 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 91/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9805\n",
      "Epoch 00091: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2201 - accuracy: 0.9805 - val_loss: 0.5531 - val_accuracy: 0.9003 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 92/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9826\n",
      "Epoch 00092: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2106 - accuracy: 0.9826 - val_loss: 0.5667 - val_accuracy: 0.8948 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 93/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2131 - accuracy: 0.9826\n",
      "Epoch 00093: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2130 - accuracy: 0.9826 - val_loss: 0.5399 - val_accuracy: 0.9017 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 94/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9799\n",
      "Epoch 00094: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2174 - accuracy: 0.9799 - val_loss: 0.5401 - val_accuracy: 0.8984 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 95/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9797\n",
      "Epoch 00095: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2184 - accuracy: 0.9797 - val_loss: 0.5889 - val_accuracy: 0.8924 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 96/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9816\n",
      "Epoch 00096: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2153 - accuracy: 0.9816 - val_loss: 0.5225 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 97/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9809\n",
      "Epoch 00097: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2183 - accuracy: 0.9809 - val_loss: 0.5519 - val_accuracy: 0.9015 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 98/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9832\n",
      "Epoch 00098: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2124 - accuracy: 0.9832 - val_loss: 0.5494 - val_accuracy: 0.9013 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 99/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9828\n",
      "Epoch 00099: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2128 - accuracy: 0.9829 - val_loss: 0.5374 - val_accuracy: 0.9017 - lr: 0.0100\n",
      "new lf : 0.010000000000000002\n",
      "Epoch 100/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9805\n",
      "Epoch 00100: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.2189 - accuracy: 0.9805 - val_loss: 0.5261 - val_accuracy: 0.9087 - lr: 0.0100\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 101/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9891\n",
      "Epoch 00101: val_accuracy improved from 0.92370 to 0.92950, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1957 - accuracy: 0.9891 - val_loss: 0.4202 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 102/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9954\n",
      "Epoch 00102: val_accuracy improved from 0.92950 to 0.93300, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1794 - accuracy: 0.9954 - val_loss: 0.4118 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 103/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9961\n",
      "Epoch 00103: val_accuracy did not improve from 0.93300\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1757 - accuracy: 0.9961 - val_loss: 0.4131 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 104/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9971\n",
      "Epoch 00104: val_accuracy improved from 0.93300 to 0.93430, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1721 - accuracy: 0.9971 - val_loss: 0.4105 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 105/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9972\n",
      "Epoch 00105: val_accuracy did not improve from 0.93430\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1702 - accuracy: 0.9973 - val_loss: 0.4093 - val_accuracy: 0.9326 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 106/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9972\n",
      "Epoch 00106: val_accuracy improved from 0.93430 to 0.93470, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1687 - accuracy: 0.9972 - val_loss: 0.4088 - val_accuracy: 0.9347 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 107/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1660 - accuracy: 0.9978\n",
      "Epoch 00107: val_accuracy did not improve from 0.93470\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1660 - accuracy: 0.9978 - val_loss: 0.4078 - val_accuracy: 0.9340 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 108/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9983\n",
      "Epoch 00108: val_accuracy did not improve from 0.93470\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1639 - accuracy: 0.9984 - val_loss: 0.4070 - val_accuracy: 0.9337 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 109/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9981\n",
      "Epoch 00109: val_accuracy did not improve from 0.93470\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1629 - accuracy: 0.9981 - val_loss: 0.4064 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 110/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9985\n",
      "Epoch 00110: val_accuracy did not improve from 0.93470\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1609 - accuracy: 0.9985 - val_loss: 0.4090 - val_accuracy: 0.9335 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 111/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9986\n",
      "Epoch 00111: val_accuracy improved from 0.93470 to 0.93620, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1596 - accuracy: 0.9986 - val_loss: 0.4071 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 112/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9987\n",
      "Epoch 00112: val_accuracy did not improve from 0.93620\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1580 - accuracy: 0.9987 - val_loss: 0.4111 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 113/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9986\n",
      "Epoch 00113: val_accuracy did not improve from 0.93620\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1573 - accuracy: 0.9986 - val_loss: 0.4058 - val_accuracy: 0.9354 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 114/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9992\n",
      "Epoch 00114: val_accuracy improved from 0.93620 to 0.93640, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1554 - accuracy: 0.9992 - val_loss: 0.4040 - val_accuracy: 0.9364 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 115/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9991\n",
      "Epoch 00115: val_accuracy improved from 0.93640 to 0.93650, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1545 - accuracy: 0.9991 - val_loss: 0.4051 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 116/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9993\n",
      "Epoch 00116: val_accuracy did not improve from 0.93650\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1530 - accuracy: 0.9993 - val_loss: 0.4046 - val_accuracy: 0.9355 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 117/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1524 - accuracy: 0.9989\n",
      "Epoch 00117: val_accuracy improved from 0.93650 to 0.93690, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1524 - accuracy: 0.9990 - val_loss: 0.4033 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 118/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9989\n",
      "Epoch 00118: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1513 - accuracy: 0.9989 - val_loss: 0.4039 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 119/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9991\n",
      "Epoch 00119: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1500 - accuracy: 0.9991 - val_loss: 0.4045 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 120/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9995\n",
      "Epoch 00120: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1486 - accuracy: 0.9995 - val_loss: 0.4028 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 121/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9994\n",
      "Epoch 00121: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1478 - accuracy: 0.9994 - val_loss: 0.4013 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 122/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9992\n",
      "Epoch 00122: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1471 - accuracy: 0.9992 - val_loss: 0.4045 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 123/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9995\n",
      "Epoch 00123: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1458 - accuracy: 0.9995 - val_loss: 0.4010 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 124/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9995\n",
      "Epoch 00124: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1445 - accuracy: 0.9995 - val_loss: 0.4025 - val_accuracy: 0.9366 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 125/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9994\n",
      "Epoch 00125: val_accuracy did not improve from 0.93690\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1437 - accuracy: 0.9995 - val_loss: 0.4009 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 126/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 0.9994\n",
      "Epoch 00126: val_accuracy improved from 0.93690 to 0.93710, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1428 - accuracy: 0.9994 - val_loss: 0.4010 - val_accuracy: 0.9371 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 127/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9993\n",
      "Epoch 00127: val_accuracy did not improve from 0.93710\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1420 - accuracy: 0.9993 - val_loss: 0.3996 - val_accuracy: 0.9370 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 128/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9996\n",
      "Epoch 00128: val_accuracy did not improve from 0.93710\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1406 - accuracy: 0.9996 - val_loss: 0.3966 - val_accuracy: 0.9367 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 129/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9997\n",
      "Epoch 00129: val_accuracy improved from 0.93710 to 0.93760, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1396 - accuracy: 0.9997 - val_loss: 0.3975 - val_accuracy: 0.9376 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 130/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9996\n",
      "Epoch 00130: val_accuracy did not improve from 0.93760\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1388 - accuracy: 0.9996 - val_loss: 0.3966 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 131/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9998\n",
      "Epoch 00131: val_accuracy improved from 0.93760 to 0.93820, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1375 - accuracy: 0.9998 - val_loss: 0.3994 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 132/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9997\n",
      "Epoch 00132: val_accuracy improved from 0.93820 to 0.93890, saving model to ./model/20201103_213554/best_val_acc.hdf5\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.1368 - accuracy: 0.9997 - val_loss: 0.4009 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 133/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9998\n",
      "Epoch 00133: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1359 - accuracy: 0.9998 - val_loss: 0.3986 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 134/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.9997\n",
      "Epoch 00134: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1350 - accuracy: 0.9998 - val_loss: 0.3964 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 135/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9997\n",
      "Epoch 00135: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1343 - accuracy: 0.9997 - val_loss: 0.3981 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 136/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9995\n",
      "Epoch 00136: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1335 - accuracy: 0.9995 - val_loss: 0.3971 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 137/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9996\n",
      "Epoch 00137: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1326 - accuracy: 0.9996 - val_loss: 0.3972 - val_accuracy: 0.9366 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 138/200\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9998\n",
      "Epoch 00138: val_accuracy did not improve from 0.93890\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3.43558\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.1313 - accuracy: 0.9998 - val_loss: 0.3977 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "new lf : 0.0010000000000000002\n",
      "Epoch 139/200\n",
      "175/313 [===============>..............] - ETA: 8s - loss: 0.1308 - accuracy: 0.9996"
     ]
    }
   ],
   "source": [
    "for noise_ratio in [0.1, 0.2, 0.3]:\n",
    "    noise_ratio = 0.1\n",
    "    cifar10_data = CIFAR10Data()\n",
    "    data = cifar10_data.get_noisy_data(noise_ratio)\n",
    "\n",
    "    solver = Solver(model, data)\n",
    "    solver.name += \"_noise{}\".format(noise_ratio)\n",
    "    history = solver.train(epochs=200, batch_size=128, data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
