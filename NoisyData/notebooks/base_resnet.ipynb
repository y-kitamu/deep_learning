{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kitamura/.local/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:44: UserWarning: You are currently using a nightly version of TensorFlow (2.2.0-dev20200403). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import noisydata\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(x_train, y_train, gt_y_train, start_idx=0, rows=5, cols=7):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 5, rows * 5))\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            idx = row * cols + col + start_idx\n",
    "            axes[row][col].imshow(x_train[idx])\n",
    "            axes[row][col].set_title(\"label = {}, true = {}\".format(y_train[idx, 0], gt_y_train[idx, 0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-03 17:07:03 (function load_dataset in file ../noisydata/train.py at line 119)] Successfully load noised cifar10. train = 45000, val = 5000, test = 10000\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 90)] Model name = pre_act_res_net32\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 91)] Loss       = sparse_categorical_crossentropy\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 92)] Optimizer  = AdamW\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 93)] Epochs     = 300\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 94)] Batch size = 160\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 95)] CSV log    = /home/kitamura/work/DeepLearning/NoisyData/noisydata/../log/20201103_170703.csv\n",
      "[2020-11-03 17:07:03 (function log_trainer_info in file ../noisydata/train.py at line 96)] Output dir = /home/kitamura/work/DeepLearning/NoisyData/noisydata/../models/20201103_170703\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "unit1 (Sequential)           (None, 32, 32, 32)        93760     \n",
      "_________________________________________________________________\n",
      "unit2 (Sequential)           (None, 16, 16, 64)        361536    \n",
      "_________________________________________________________________\n",
      "unit3 (Sequential)           (None, 8, 8, 128)         1439872   \n",
      "_________________________________________________________________\n",
      "bn (BatchNormalization)      (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "gap (GlobalAveragePooling2D) (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,897,866\n",
      "Trainable params: 1,893,322\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = noisydata.models.MyModel()\n",
    "model = noisydata.models.PreActResNet32()\n",
    "#loss_func = noisydata.loss.NoisyDataLoss(1.2, 0.8, np.ones(10) / 10)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "# optimizer = tfa.optimizers.SGDW(\n",
    "#     weight_decay=1e-4,\n",
    "#     learning_rate=0.01,\n",
    "#     momentum=0.9)\n",
    "lr_scheduler = None\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-4)\n",
    "\n",
    "trainer = noisydata.train.Trainer(\n",
    "    model=model,\n",
    "    loss=loss_func,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    batch_size=160,\n",
    "    is_one_hot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 / 45000WARNING:tensorflow:Layer pre_act_res_net32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[2020-11-03 17:07:36 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:07:36 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:07:36 (function train in file ../noisydata/train.py at line 205)] Epoch : 1, Loss : 1.620, Accuracy : 39.320, Val Loss : 4.978, Val Accuracy : 10.640, Elapsed Time : 31.64 [sec]\n",
      "[2020-11-03 17:08:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:08:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:08:06 (function train in file ../noisydata/train.py at line 205)] Epoch : 2, Loss : 1.236, Accuracy : 55.193, Val Loss : 3.234, Val Accuracy : 27.740, Elapsed Time : 29.81 [sec]\n",
      "[2020-11-03 17:08:36 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:08:36 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:08:36 (function train in file ../noisydata/train.py at line 205)] Epoch : 3, Loss : 1.072, Accuracy : 61.284, Val Loss : 1.804, Val Accuracy : 46.940, Elapsed Time : 30.14 [sec]\n",
      "[2020-11-03 17:09:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:09:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:09:06 (function train in file ../noisydata/train.py at line 205)] Epoch : 4, Loss : 0.968, Accuracy : 65.076, Val Loss : 1.622, Val Accuracy : 52.800, Elapsed Time : 29.80 [sec]\n",
      "[2020-11-03 17:09:36 (function train in file ../noisydata/train.py at line 205)] Epoch : 5, Loss : 0.892, Accuracy : 67.993, Val Loss : 1.623, Val Accuracy : 49.840, Elapsed Time : 29.89 [sec]\n",
      "[2020-11-03 17:10:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:10:06 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:10:06 (function train in file ../noisydata/train.py at line 205)] Epoch : 6, Loss : 0.826, Accuracy : 70.300, Val Loss : 1.235, Val Accuracy : 59.260, Elapsed Time : 30.01 [sec]\n",
      "[2020-11-03 17:10:35 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:10:35 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:10:35 (function train in file ../noisydata/train.py at line 205)] Epoch : 7, Loss : 0.773, Accuracy : 72.389, Val Loss : 1.008, Val Accuracy : 65.740, Elapsed Time : 29.62 [sec]\n",
      "[2020-11-03 17:11:05 (function train in file ../noisydata/train.py at line 205)] Epoch : 8, Loss : 0.720, Accuracy : 74.420, Val Loss : 1.297, Val Accuracy : 59.500, Elapsed Time : 29.36 [sec]\n",
      "[2020-11-03 17:11:35 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:11:35 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:11:35 (function train in file ../noisydata/train.py at line 205)] Epoch : 9, Loss : 0.679, Accuracy : 75.864, Val Loss : 0.961, Val Accuracy : 66.200, Elapsed Time : 30.09 [sec]\n",
      "[2020-11-03 17:12:05 (function train in file ../noisydata/train.py at line 205)] Epoch : 10, Loss : 0.635, Accuracy : 77.596, Val Loss : 1.362, Val Accuracy : 58.640, Elapsed Time : 30.05 [sec]\n",
      "[2020-11-03 17:12:35 (function train in file ../noisydata/train.py at line 205)] Epoch : 11, Loss : 0.596, Accuracy : 79.107, Val Loss : 1.084, Val Accuracy : 65.660, Elapsed Time : 29.86 [sec]\n",
      "[2020-11-03 17:13:04 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:13:04 (function train in file ../noisydata/train.py at line 205)] Epoch : 12, Loss : 0.567, Accuracy : 80.062, Val Loss : 1.067, Val Accuracy : 67.020, Elapsed Time : 29.65 [sec]\n",
      "[2020-11-03 17:13:34 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:13:34 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:13:34 (function train in file ../noisydata/train.py at line 205)] Epoch : 13, Loss : 0.534, Accuracy : 81.262, Val Loss : 0.791, Val Accuracy : 73.560, Elapsed Time : 29.91 [sec]\n",
      "[2020-11-03 17:14:05 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:14:05 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:14:05 (function train in file ../noisydata/train.py at line 205)] Epoch : 14, Loss : 0.508, Accuracy : 82.189, Val Loss : 0.728, Val Accuracy : 76.160, Elapsed Time : 30.21 [sec]\n",
      "[2020-11-03 17:14:34 (function train in file ../noisydata/train.py at line 205)] Epoch : 15, Loss : 0.475, Accuracy : 83.498, Val Loss : 0.866, Val Accuracy : 72.780, Elapsed Time : 29.53 [sec]\n",
      "[2020-11-03 17:15:03 (function train in file ../noisydata/train.py at line 205)] Epoch : 16, Loss : 0.455, Accuracy : 84.162, Val Loss : 0.783, Val Accuracy : 75.020, Elapsed Time : 29.30 [sec]\n",
      "[2020-11-03 17:15:33 (function train in file ../noisydata/train.py at line 205)] Epoch : 17, Loss : 0.436, Accuracy : 84.529, Val Loss : 0.749, Val Accuracy : 74.480, Elapsed Time : 29.64 [sec]\n",
      "[2020-11-03 17:16:03 (function train in file ../noisydata/train.py at line 205)] Epoch : 18, Loss : 0.410, Accuracy : 85.727, Val Loss : 1.324, Val Accuracy : 64.000, Elapsed Time : 29.76 [sec]\n",
      "[2020-11-03 17:16:33 (function train in file ../noisydata/train.py at line 205)] Epoch : 19, Loss : 0.398, Accuracy : 85.931, Val Loss : 0.810, Val Accuracy : 73.240, Elapsed Time : 30.08 [sec]\n",
      "[2020-11-03 17:17:03 (function train in file ../noisydata/train.py at line 205)] Epoch : 20, Loss : 0.381, Accuracy : 86.844, Val Loss : 1.277, Val Accuracy : 65.820, Elapsed Time : 29.94 [sec]\n",
      "[2020-11-03 17:17:33 (function train in file ../noisydata/train.py at line 205)] Epoch : 21, Loss : 0.359, Accuracy : 87.447, Val Loss : 0.817, Val Accuracy : 73.780, Elapsed Time : 29.53 [sec]\n",
      "[2020-11-03 17:18:02 (function train in file ../noisydata/train.py at line 205)] Epoch : 22, Loss : 0.351, Accuracy : 87.780, Val Loss : 0.996, Val Accuracy : 70.580, Elapsed Time : 29.30 [sec]\n",
      "[2020-11-03 17:18:32 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_acc\n",
      "[2020-11-03 17:18:32 (function _save_weight in file ../noisydata/train.py at line 171)] Save model : best_loss\n",
      "[2020-11-03 17:18:32 (function train in file ../noisydata/train.py at line 205)] Epoch : 23, Loss : 0.338, Accuracy : 88.127, Val Loss : 0.605, Val Accuracy : 79.520, Elapsed Time : 29.93 [sec]\n",
      " 31200 / 45000"
     ]
    }
   ],
   "source": [
    "noisydata.utility.run_debug(\n",
    "    lambda : trainer.train()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "282/282 [==============================] - 15s 54ms/step - loss: 1.8529 - accuracy: 0.3742 - val_loss: 4.7742 - val_accuracy: 0.1324\n",
      "Epoch 2/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.5505 - accuracy: 0.4714 - val_loss: 2.5160 - val_accuracy: 0.2430\n",
      "Epoch 3/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.5632 - accuracy: 0.4741 - val_loss: 2.3590 - val_accuracy: 0.2332\n",
      "Epoch 4/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 1.5661 - accuracy: 0.4572 - val_loss: 2.1669 - val_accuracy: 0.2766\n",
      "Epoch 5/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.5635 - accuracy: 0.4700 - val_loss: 1.5101 - val_accuracy: 0.4626\n",
      "Epoch 6/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.3421 - accuracy: 0.5462 - val_loss: 1.5280 - val_accuracy: 0.4584\n",
      "Epoch 7/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.2002 - accuracy: 0.5919 - val_loss: 1.9882 - val_accuracy: 0.5050\n",
      "Epoch 8/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 1.0982 - accuracy: 0.6264 - val_loss: 2.3070 - val_accuracy: 0.2574\n",
      "Epoch 9/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.3833 - accuracy: 0.5359 - val_loss: 43.7860 - val_accuracy: 0.1308\n",
      "Epoch 10/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.2853 - accuracy: 0.5590 - val_loss: 1.3790 - val_accuracy: 0.5024\n",
      "Epoch 11/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 1.0784 - accuracy: 0.6334 - val_loss: 1.2616 - val_accuracy: 0.5614\n",
      "Epoch 12/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.9389 - accuracy: 0.6784 - val_loss: 2.2971 - val_accuracy: 0.5178\n",
      "Epoch 13/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.8545 - accuracy: 0.7089 - val_loss: 1.1768 - val_accuracy: 0.6026\n",
      "Epoch 14/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.7401 - accuracy: 0.7451 - val_loss: 1.0042 - val_accuracy: 0.6522\n",
      "Epoch 15/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.6641 - accuracy: 0.7724 - val_loss: 0.8918 - val_accuracy: 0.6948\n",
      "Epoch 16/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.5718 - accuracy: 0.7996 - val_loss: 1.0390 - val_accuracy: 0.6564\n",
      "Epoch 17/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.5090 - accuracy: 0.8225 - val_loss: 1.0187 - val_accuracy: 0.6738\n",
      "Epoch 18/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.4641 - accuracy: 0.8379 - val_loss: 1.4026 - val_accuracy: 0.5926\n",
      "Epoch 19/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.4187 - accuracy: 0.8538 - val_loss: 1.4396 - val_accuracy: 0.5800\n",
      "Epoch 20/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.4830 - accuracy: 0.8323 - val_loss: 0.9884 - val_accuracy: 0.6958\n",
      "Epoch 21/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.3504 - accuracy: 0.8776 - val_loss: 0.9407 - val_accuracy: 0.7264\n",
      "Epoch 22/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.3048 - accuracy: 0.8934 - val_loss: 1.1533 - val_accuracy: 0.6874\n",
      "Epoch 23/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.2796 - accuracy: 0.9031 - val_loss: 1.0314 - val_accuracy: 0.7038\n",
      "Epoch 24/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.2494 - accuracy: 0.9138 - val_loss: 1.1667 - val_accuracy: 0.6762\n",
      "Epoch 25/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.2344 - accuracy: 0.9173 - val_loss: 1.2919 - val_accuracy: 0.6584\n",
      "Epoch 26/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.2203 - accuracy: 0.9230 - val_loss: 1.1954 - val_accuracy: 0.6874\n",
      "Epoch 27/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1980 - accuracy: 0.9313 - val_loss: 1.1680 - val_accuracy: 0.7054\n",
      "Epoch 28/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1884 - accuracy: 0.9344 - val_loss: 1.3765 - val_accuracy: 0.6642\n",
      "Epoch 29/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1808 - accuracy: 0.9368 - val_loss: 1.5147 - val_accuracy: 0.6328\n",
      "Epoch 30/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1619 - accuracy: 0.9439 - val_loss: 1.1531 - val_accuracy: 0.7158\n",
      "Epoch 31/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1605 - accuracy: 0.9446 - val_loss: 1.3020 - val_accuracy: 0.6838\n",
      "Epoch 32/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1508 - accuracy: 0.9472 - val_loss: 1.5871 - val_accuracy: 0.6594\n",
      "Epoch 33/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1645 - accuracy: 0.9432 - val_loss: 1.3511 - val_accuracy: 0.6816\n",
      "Epoch 34/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1322 - accuracy: 0.9540 - val_loss: 1.1936 - val_accuracy: 0.7190\n",
      "Epoch 35/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1371 - accuracy: 0.9524 - val_loss: 1.2661 - val_accuracy: 0.7072\n",
      "Epoch 36/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1309 - accuracy: 0.9544 - val_loss: 1.5017 - val_accuracy: 0.6666\n",
      "Epoch 37/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1259 - accuracy: 0.9563 - val_loss: 1.2041 - val_accuracy: 0.7156\n",
      "Epoch 38/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1298 - accuracy: 0.9556 - val_loss: 1.1774 - val_accuracy: 0.7224\n",
      "Epoch 39/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1255 - accuracy: 0.9571 - val_loss: 1.2043 - val_accuracy: 0.7152\n",
      "Epoch 40/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1112 - accuracy: 0.9617 - val_loss: 2.1145 - val_accuracy: 0.5900\n",
      "Epoch 41/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.7997 - accuracy: 0.7305 - val_loss: 1.2598 - val_accuracy: 0.6168\n",
      "Epoch 42/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.5612 - accuracy: 0.8074 - val_loss: 1.0797 - val_accuracy: 0.6704\n",
      "Epoch 43/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.2068 - accuracy: 0.9295 - val_loss: 1.0431 - val_accuracy: 0.7180\n",
      "Epoch 44/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1137 - accuracy: 0.9611 - val_loss: 1.2047 - val_accuracy: 0.7086\n",
      "Epoch 45/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1070 - accuracy: 0.9632 - val_loss: 1.2495 - val_accuracy: 0.7158\n",
      "Epoch 46/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1018 - accuracy: 0.9654 - val_loss: 1.2179 - val_accuracy: 0.7086\n",
      "Epoch 47/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0993 - accuracy: 0.9652 - val_loss: 1.1619 - val_accuracy: 0.7348\n",
      "Epoch 48/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0973 - accuracy: 0.9662 - val_loss: 1.6826 - val_accuracy: 0.6338\n",
      "Epoch 49/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0983 - accuracy: 0.9674 - val_loss: 1.1627 - val_accuracy: 0.7326\n",
      "Epoch 50/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1020 - accuracy: 0.9643 - val_loss: 1.1482 - val_accuracy: 0.7392\n",
      "Epoch 51/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1002 - accuracy: 0.9652 - val_loss: 1.2212 - val_accuracy: 0.7114\n",
      "Epoch 52/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1065 - accuracy: 0.9637 - val_loss: 1.1945 - val_accuracy: 0.7260\n",
      "Epoch 53/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1065 - accuracy: 0.9634 - val_loss: 1.2020 - val_accuracy: 0.7238\n",
      "Epoch 54/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1068 - accuracy: 0.9632 - val_loss: 1.9198 - val_accuracy: 0.6102\n",
      "Epoch 55/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1120 - accuracy: 0.9623 - val_loss: 1.4381 - val_accuracy: 0.6534\n",
      "Epoch 56/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1053 - accuracy: 0.9635 - val_loss: 1.3373 - val_accuracy: 0.7080\n",
      "Epoch 57/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1006 - accuracy: 0.9656 - val_loss: 1.3263 - val_accuracy: 0.7048\n",
      "Epoch 58/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0960 - accuracy: 0.9672 - val_loss: 1.1728 - val_accuracy: 0.7228\n",
      "Epoch 59/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1036 - accuracy: 0.9645 - val_loss: 1.2918 - val_accuracy: 0.7120\n",
      "Epoch 60/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0954 - accuracy: 0.9672 - val_loss: 1.4322 - val_accuracy: 0.6790\n",
      "Epoch 61/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 1.5315 - val_accuracy: 0.6576\n",
      "Epoch 62/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 1.6183 - val_accuracy: 0.6750\n",
      "Epoch 63/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0958 - accuracy: 0.9670 - val_loss: 1.3193 - val_accuracy: 0.7116\n",
      "Epoch 64/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 1.3002 - val_accuracy: 0.7220\n",
      "Epoch 65/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0989 - accuracy: 0.9672 - val_loss: 1.3269 - val_accuracy: 0.7016\n",
      "Epoch 66/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 1.6357 - val_accuracy: 0.6670\n",
      "Epoch 67/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0940 - accuracy: 0.9687 - val_loss: 1.4533 - val_accuracy: 0.6822\n",
      "Epoch 68/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0985 - accuracy: 0.9662 - val_loss: 1.3226 - val_accuracy: 0.7144\n",
      "Epoch 69/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 1.2484 - val_accuracy: 0.7204\n",
      "Epoch 70/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0920 - accuracy: 0.9689 - val_loss: 1.1821 - val_accuracy: 0.7404\n",
      "Epoch 71/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0833 - accuracy: 0.9724 - val_loss: 1.4116 - val_accuracy: 0.6864\n",
      "Epoch 72/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0929 - accuracy: 0.9683 - val_loss: 1.5015 - val_accuracy: 0.6708\n",
      "Epoch 73/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 1.2315 - val_accuracy: 0.7126\n",
      "Epoch 74/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0826 - accuracy: 0.9719 - val_loss: 1.4426 - val_accuracy: 0.6874\n",
      "Epoch 75/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0855 - accuracy: 0.9713 - val_loss: 1.9052 - val_accuracy: 0.6240\n",
      "Epoch 76/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.1165 - accuracy: 0.9620 - val_loss: 1.5488 - val_accuracy: 0.6782\n",
      "Epoch 77/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0940 - accuracy: 0.9683 - val_loss: 1.4748 - val_accuracy: 0.7032\n",
      "Epoch 78/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0789 - accuracy: 0.9735 - val_loss: 1.4680 - val_accuracy: 0.6850\n",
      "Epoch 79/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0803 - accuracy: 0.9729 - val_loss: 1.3472 - val_accuracy: 0.7134\n",
      "Epoch 80/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0856 - accuracy: 0.9700 - val_loss: 1.6092 - val_accuracy: 0.6774\n",
      "Epoch 81/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0891 - accuracy: 0.9708 - val_loss: 1.2563 - val_accuracy: 0.7278\n",
      "Epoch 82/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.2116 - accuracy: 0.9321 - val_loss: 1.3493 - val_accuracy: 0.6456\n",
      "Epoch 83/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1312 - accuracy: 0.9540 - val_loss: 1.1271 - val_accuracy: 0.7332\n",
      "Epoch 84/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 1.4784 - val_accuracy: 0.6788\n",
      "Epoch 85/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0671 - accuracy: 0.9777 - val_loss: 1.3839 - val_accuracy: 0.7104\n",
      "Epoch 86/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0743 - accuracy: 0.9745 - val_loss: 1.2515 - val_accuracy: 0.7276\n",
      "Epoch 87/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0777 - accuracy: 0.9740 - val_loss: 1.6213 - val_accuracy: 0.6526\n",
      "Epoch 88/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0733 - accuracy: 0.9750 - val_loss: 1.3924 - val_accuracy: 0.7008\n",
      "Epoch 89/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 1.5807 - val_accuracy: 0.6696\n",
      "Epoch 90/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0852 - accuracy: 0.9712 - val_loss: 1.4159 - val_accuracy: 0.6828\n",
      "Epoch 91/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0822 - accuracy: 0.9718 - val_loss: 1.2995 - val_accuracy: 0.7068\n",
      "Epoch 92/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0792 - accuracy: 0.9728 - val_loss: 1.1800 - val_accuracy: 0.7300\n",
      "Epoch 93/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 1.2475 - val_accuracy: 0.7342\n",
      "Epoch 94/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.1906 - accuracy: 0.9365 - val_loss: 1.4699 - val_accuracy: 0.6716\n",
      "Epoch 95/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 1.3385 - val_accuracy: 0.7094\n",
      "Epoch 96/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0728 - accuracy: 0.9752 - val_loss: 1.2338 - val_accuracy: 0.7252\n",
      "Epoch 97/200\n",
      "282/282 [==============================] - 15s 54ms/step - loss: 0.0707 - accuracy: 0.9763 - val_loss: 1.5511 - val_accuracy: 0.6662\n",
      "Epoch 98/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 1.1592 - val_accuracy: 0.7442\n",
      "Epoch 99/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0755 - accuracy: 0.9737 - val_loss: 1.3952 - val_accuracy: 0.7072\n",
      "Epoch 100/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 1.2306 - val_accuracy: 0.7252\n",
      "Epoch 101/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 1.4743 - val_accuracy: 0.6966\n",
      "Epoch 102/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 1.2352 - val_accuracy: 0.7124\n",
      "Epoch 103/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 1.3202 - val_accuracy: 0.7010\n",
      "Epoch 104/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0784 - accuracy: 0.9722 - val_loss: 1.3725 - val_accuracy: 0.7154\n",
      "Epoch 105/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0826 - accuracy: 0.9723 - val_loss: 1.2522 - val_accuracy: 0.7316\n",
      "Epoch 106/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0774 - accuracy: 0.9721 - val_loss: 1.2868 - val_accuracy: 0.7252\n",
      "Epoch 107/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0755 - accuracy: 0.9746 - val_loss: 1.2169 - val_accuracy: 0.7324\n",
      "Epoch 108/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0722 - accuracy: 0.9758 - val_loss: 1.3481 - val_accuracy: 0.7004\n",
      "Epoch 109/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 1.4608 - val_accuracy: 0.6894\n",
      "Epoch 110/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0820 - accuracy: 0.9721 - val_loss: 1.3264 - val_accuracy: 0.7124\n",
      "Epoch 111/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0774 - accuracy: 0.9743 - val_loss: 1.6162 - val_accuracy: 0.6772\n",
      "Epoch 112/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0796 - accuracy: 0.9731 - val_loss: 1.4106 - val_accuracy: 0.6994\n",
      "Epoch 113/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0783 - accuracy: 0.9738 - val_loss: 1.6436 - val_accuracy: 0.6784\n",
      "Epoch 114/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0765 - accuracy: 0.9744 - val_loss: 1.3464 - val_accuracy: 0.6960\n",
      "Epoch 115/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0808 - accuracy: 0.9724 - val_loss: 1.3511 - val_accuracy: 0.7186\n",
      "Epoch 116/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0833 - accuracy: 0.9727 - val_loss: 1.1343 - val_accuracy: 0.7418\n",
      "Epoch 117/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0741 - accuracy: 0.9755 - val_loss: 2.0704 - val_accuracy: 0.6158\n",
      "Epoch 118/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0778 - accuracy: 0.9729 - val_loss: 1.4771 - val_accuracy: 0.6996\n",
      "Epoch 119/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 1.4750 - val_accuracy: 0.6870\n",
      "Epoch 120/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0736 - accuracy: 0.9756 - val_loss: 1.3856 - val_accuracy: 0.6916\n",
      "Epoch 121/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0739 - accuracy: 0.9756 - val_loss: 1.2046 - val_accuracy: 0.7440\n",
      "Epoch 122/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0748 - accuracy: 0.9749 - val_loss: 1.3839 - val_accuracy: 0.7120\n",
      "Epoch 123/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0777 - accuracy: 0.9742 - val_loss: 1.3606 - val_accuracy: 0.7090\n",
      "Epoch 124/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0781 - accuracy: 0.9738 - val_loss: 1.2720 - val_accuracy: 0.7280\n",
      "Epoch 125/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0788 - accuracy: 0.9720 - val_loss: 1.3912 - val_accuracy: 0.7126\n",
      "Epoch 126/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0760 - accuracy: 0.9744 - val_loss: 1.2652 - val_accuracy: 0.7256\n",
      "Epoch 127/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0724 - accuracy: 0.9756 - val_loss: 1.3711 - val_accuracy: 0.7026\n",
      "Epoch 128/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 1.4771 - val_accuracy: 0.6860\n",
      "Epoch 129/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0738 - accuracy: 0.9756 - val_loss: 1.4753 - val_accuracy: 0.6998\n",
      "Epoch 130/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0717 - accuracy: 0.9768 - val_loss: 1.4363 - val_accuracy: 0.6892\n",
      "Epoch 131/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0853 - accuracy: 0.9712 - val_loss: 1.2195 - val_accuracy: 0.7192\n",
      "Epoch 132/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 1.2796 - val_accuracy: 0.7320\n",
      "Epoch 133/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0705 - accuracy: 0.9758 - val_loss: 1.3180 - val_accuracy: 0.7220\n",
      "Epoch 134/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0771 - accuracy: 0.9736 - val_loss: 1.2349 - val_accuracy: 0.7280\n",
      "Epoch 135/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0714 - accuracy: 0.9758 - val_loss: 1.1971 - val_accuracy: 0.7472\n",
      "Epoch 136/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0720 - accuracy: 0.9760 - val_loss: 1.2561 - val_accuracy: 0.7240\n",
      "Epoch 137/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 1.6461 - val_accuracy: 0.6730\n",
      "Epoch 138/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0747 - accuracy: 0.9753 - val_loss: 1.1416 - val_accuracy: 0.7332\n",
      "Epoch 139/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 1.5389 - val_accuracy: 0.7016\n",
      "Epoch 140/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0730 - accuracy: 0.9752 - val_loss: 1.4216 - val_accuracy: 0.7050\n",
      "Epoch 141/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0767 - accuracy: 0.9738 - val_loss: 1.1485 - val_accuracy: 0.7366\n",
      "Epoch 142/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0763 - accuracy: 0.9747 - val_loss: 1.3260 - val_accuracy: 0.7026\n",
      "Epoch 143/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 1.2439 - val_accuracy: 0.7182\n",
      "Epoch 144/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 1.3172 - val_accuracy: 0.7226\n",
      "Epoch 145/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0751 - accuracy: 0.9749 - val_loss: 1.2821 - val_accuracy: 0.7222\n",
      "Epoch 146/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0773 - accuracy: 0.9729 - val_loss: 1.3594 - val_accuracy: 0.7130\n",
      "Epoch 147/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 1.4326 - val_accuracy: 0.7018\n",
      "Epoch 148/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0701 - accuracy: 0.9762 - val_loss: 1.2423 - val_accuracy: 0.7198\n",
      "Epoch 149/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0756 - accuracy: 0.9741 - val_loss: 1.3772 - val_accuracy: 0.7030\n",
      "Epoch 150/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 1.5757 - val_accuracy: 0.6616\n",
      "Epoch 151/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0719 - accuracy: 0.9746 - val_loss: 1.2578 - val_accuracy: 0.7314\n",
      "Epoch 152/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 1.3537 - val_accuracy: 0.7058\n",
      "Epoch 153/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 1.2568 - val_accuracy: 0.7232\n",
      "Epoch 154/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0758 - accuracy: 0.9743 - val_loss: 1.4405 - val_accuracy: 0.6948\n",
      "Epoch 155/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0691 - accuracy: 0.9765 - val_loss: 1.3875 - val_accuracy: 0.6940\n",
      "Epoch 156/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0782 - accuracy: 0.9732 - val_loss: 1.2071 - val_accuracy: 0.7310\n",
      "Epoch 157/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0703 - accuracy: 0.9763 - val_loss: 1.3602 - val_accuracy: 0.7040\n",
      "Epoch 158/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0743 - accuracy: 0.9744 - val_loss: 1.1778 - val_accuracy: 0.7366\n",
      "Epoch 159/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0677 - accuracy: 0.9775 - val_loss: 1.5977 - val_accuracy: 0.6830\n",
      "Epoch 160/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0655 - accuracy: 0.9779 - val_loss: 1.7903 - val_accuracy: 0.6446\n",
      "Epoch 161/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 1.6764 - val_accuracy: 0.6568\n",
      "Epoch 162/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0796 - accuracy: 0.9739 - val_loss: 1.1564 - val_accuracy: 0.7398\n",
      "Epoch 163/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 1.1526 - val_accuracy: 0.7300\n",
      "Epoch 164/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0735 - accuracy: 0.9755 - val_loss: 1.6399 - val_accuracy: 0.6652\n",
      "Epoch 165/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0671 - accuracy: 0.9774 - val_loss: 1.4633 - val_accuracy: 0.6996\n",
      "Epoch 166/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0709 - accuracy: 0.9758 - val_loss: 1.1606 - val_accuracy: 0.7384\n",
      "Epoch 167/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0654 - accuracy: 0.9782 - val_loss: 1.3236 - val_accuracy: 0.7244\n",
      "Epoch 168/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0709 - accuracy: 0.9756 - val_loss: 1.2286 - val_accuracy: 0.7428\n",
      "Epoch 169/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0699 - accuracy: 0.9770 - val_loss: 1.2225 - val_accuracy: 0.7266\n",
      "Epoch 170/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0647 - accuracy: 0.9783 - val_loss: 1.3271 - val_accuracy: 0.7070\n",
      "Epoch 171/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 1.4606 - val_accuracy: 0.6970\n",
      "Epoch 172/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 1.2851 - val_accuracy: 0.7180\n",
      "Epoch 173/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 1.8128 - val_accuracy: 0.6608\n",
      "Epoch 174/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0737 - accuracy: 0.9752 - val_loss: 1.4099 - val_accuracy: 0.6958\n",
      "Epoch 175/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0701 - accuracy: 0.9761 - val_loss: 2.0810 - val_accuracy: 0.6560\n",
      "Epoch 176/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 1.4988 - val_accuracy: 0.6746\n",
      "Epoch 177/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0739 - accuracy: 0.9754 - val_loss: 1.1315 - val_accuracy: 0.7484\n",
      "Epoch 178/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0634 - accuracy: 0.9782 - val_loss: 1.2822 - val_accuracy: 0.7144\n",
      "Epoch 179/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 1.4478 - val_accuracy: 0.6860\n",
      "Epoch 180/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 1.2436 - val_accuracy: 0.7192\n",
      "Epoch 181/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0682 - accuracy: 0.9766 - val_loss: 1.2145 - val_accuracy: 0.7246\n",
      "Epoch 182/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0690 - accuracy: 0.9767 - val_loss: 1.4455 - val_accuracy: 0.6864\n",
      "Epoch 183/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0695 - accuracy: 0.9762 - val_loss: 1.3991 - val_accuracy: 0.6950\n",
      "Epoch 184/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0727 - accuracy: 0.9759 - val_loss: 1.1481 - val_accuracy: 0.7432\n",
      "Epoch 185/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 1.3452 - val_accuracy: 0.7034\n",
      "Epoch 186/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0683 - accuracy: 0.9770 - val_loss: 1.3796 - val_accuracy: 0.7138\n",
      "Epoch 187/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0669 - accuracy: 0.9774 - val_loss: 1.2645 - val_accuracy: 0.7278\n",
      "Epoch 188/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 2.3813 - val_accuracy: 0.6008\n",
      "Epoch 189/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0753 - accuracy: 0.9748 - val_loss: 1.3417 - val_accuracy: 0.6966\n",
      "Epoch 190/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0651 - accuracy: 0.9782 - val_loss: 1.3776 - val_accuracy: 0.7036\n",
      "Epoch 191/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 1.2213 - val_accuracy: 0.7334\n",
      "Epoch 192/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0692 - accuracy: 0.9765 - val_loss: 1.6093 - val_accuracy: 0.6604\n",
      "Epoch 193/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 1.2836 - val_accuracy: 0.7288\n",
      "Epoch 194/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 1.2165 - val_accuracy: 0.7218\n",
      "Epoch 195/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 1.0983 - val_accuracy: 0.7494\n",
      "Epoch 196/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 1.3064 - val_accuracy: 0.7156\n",
      "Epoch 197/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 1.8254 - val_accuracy: 0.6376\n",
      "Epoch 198/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0719 - accuracy: 0.9762 - val_loss: 1.2205 - val_accuracy: 0.7378\n",
      "Epoch 199/200\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 1.5075 - val_accuracy: 0.6876\n",
      "Epoch 200/200\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.0685 - accuracy: 0.9765 - val_loss: 1.5208 - val_accuracy: 0.6660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f180a94c390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#model = noisydata.models.PreActResNet32()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True, weights=None, input_shape=(32, 32, 3),\n",
    "    pooling=None, classes=10\n",
    ")\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    weight_decay=1e-4,\n",
    "    learning_rate=0.001,\n",
    "    #momentum=0.9\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "model.fit(x_train, y_train, batch_size=160, epochs=200, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
