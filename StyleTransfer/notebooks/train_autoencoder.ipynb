{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "import adabound\n",
    "\n",
    "import styletransfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_root_dir, transforms=None):\n",
    "        self.image_paths = list(image_root_dir.glob(\"*.jpg\"))\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def expand(self, scale):\n",
    "        self.image_paths *= scale\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = Image.open(str(self.image_paths[index]))\n",
    "        x_arr = np.asarray(x)\n",
    "        if len(x_arr.shape) == 2:\n",
    "            x = Image.fromarray(np.stack([x_arr[:], x_arr[:], x_arr[:]], axis=-1))\n",
    "        elif x_arr.shape[2] == 1:\n",
    "            x = Image.fromarray(np.stack([x_arr[:, :, 0], x_arr[:, :, 0], x_arr[:, :, 0]], axis=-1))            \n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = styletransfer.net.Net()\n",
    "#encoder = styletransfer.net.VGGEncoder()\n",
    "#net = styletransfer.net.VGGDecoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.decoder.parameters(), lr=0.001)\n",
    "#optimizer = adabound.AdaBound(net.decoder.parameters(), lr=1e-3, final_lr=0.1)\n",
    "loss_func = styletransfer.loss.Loss(lamb=5.0)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "# loss_func = nn.MSELoss()\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Grayscale(3),\n",
    "    #torchvision.transforms.Resize(32),\n",
    "    torchvision.transforms.Resize(512),\n",
    "    torchvision.transforms.RandomCrop(256),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#content_dataset = torchvision.datasets.FashionMNIST(root=\"~/dataset/fashionmnist\", train=True, download=True, transform=transform)\n",
    "#content_dataset = torchvision.datasets.MNIST(root='/content/mnist', train=True, download=True, transform=transform)\n",
    "content_dataset = ImageDataset(Path.home() / \"dataset/COCO/train2014/Resized512Color\", transform)\n",
    "content_loader = DataLoader(\n",
    "    dataset=content_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2\n",
    ")\n",
    "style_dataset = ImageDataset(Path.home() / \"dataset/AbstractGallery\", transform)\n",
    "style_dataset.expand(len(content_dataset) // len(style_dataset))\n",
    "style_loader = DataLoader(\n",
    "    dataset=style_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2\n",
    ")\n",
    "\n",
    "n_epochs = 10\n",
    "es_patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_output_dir = \"../weights/\"\n",
    "\n",
    "# encoder = encoder.to(device)\n",
    "# for param in encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image(writer, iteration, inputs, name, add_hist=False):\n",
    "    if inputs is None:\n",
    "        return\n",
    "    image = vutils.make_grid(inputs)\n",
    "    writer.add_image(\"image/{}\".format(name), image, iteration)\n",
    "    if not add_hist:\n",
    "        return\n",
    "    \n",
    "    for idx in range(inputs.shape[0]):\n",
    "        colors = inputs[idx].detach().cpu().numpy()\n",
    "        colors = colors.reshape(3, -1)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        writer.add_histogram(\"hist/{}{}_red\".format(name, idx), colors[0], iteration)\n",
    "        writer.add_histogram(\"hist/{}{}_green\".format(name, idx), colors[1], iteration)\n",
    "        writer.add_histogram(\"hist/{}{}_blue\".format(name, idx), colors[2], iteration)    \n",
    "\n",
    "def add_summary(writer, iteration, contents=None, styles=None, outputs=None):\n",
    "    add_image(writer, iteration, contents, \"content\", True)\n",
    "    add_image(writer, iteration, styles, \"style\", True)\n",
    "    add_image(writer, iteration, outputs, \"output\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "patience = es_patience\n",
    "net.train()\n",
    "g_iteration = 0\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    iteration = 0\n",
    "    for contents, styles in zip(content_loader, style_loader):\n",
    "        contents = contents.to(device=device, dtype=torch.float32)\n",
    "        styles = styles.to(device=device, dtype=torch.float32)\n",
    "        #output, s_features, trans_feat, d_features = net(contents, styles)\n",
    "        output, s_features, trans_feat, d_features = net(contents, contents)\n",
    "        loss = loss_func(s_features, trans_feat, d_features)\n",
    "        \n",
    "        #content_feat = encoder(contents)\n",
    "        #output = net(content_feat)\n",
    "        #output_feat = encoder(output)\n",
    "        #loss = loss_func(content_feat, output_feat)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        iteration += 1\n",
    "        g_iteration += 1\n",
    "        #print(\"\\r{} / {} : loss = {:.5f} ({:.5f} + {:.5f})\".format(\n",
    "        #    iteration * batch_size, len(content_dataset), epoch_loss / iteration, c_loss.item(), s_loss.item()), end=\"\")\n",
    "        writer.add_scalar(\"loss\", loss.item(), g_iteration)\n",
    "        if g_iteration % 200 == 0:\n",
    "            #add_summary(writer, g_iteration, contents, styles, output)\n",
    "            add_summary(writer, g_iteration, contents=contents, outputs=output)\n",
    "            model_output_path = \"model_{:08d}itr.pth\".format(g_iteration)\n",
    "            torch.save(net, os.path.join(model_output_dir, model_output_path))\n",
    "        print(\"\\r{} / {} : loss = {:.5f}\".format(\n",
    "              iteration * batch_size, len(content_dataset), epoch_loss / iteration), end=\"\")\n",
    "\n",
    "    model_output_path = \"model_{}epoch.pth\".format(epoch + 1)\n",
    "    torch.save(net, os.path.join(model_output_dir, model_output_path))\n",
    "    epoch_loss /= iteration\n",
    "    end_time = time.time()\n",
    "    writer.add_scalar(\"epoch_loss\", epoch_loss, epoch + 1)\n",
    "    print(\"\\nFinish Epoch {} / {}, Loss = {}, Elapsed Time = {}\".format(epoch + 1, n_epochs, epoch_loss, end_time - start_time))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        best_loss = epoch_loss\n",
    "    if epoch_loss - 1.0e-7 < best_loss:\n",
    "        torch.save(net, os.path.join(model_output_dir, \"model_bestloss.pth\"))\n",
    "        patience = es_patience\n",
    "        best_loss = epoch_loss\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Eary Stopping at Epoch {}\".format(epoch + 1))\n",
    "            break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "#test_content_set = torchvision.datasets.FashionMNIST(root=\"~/dataset/fashionmnist\", train=False, download=True, transform=transform)\n",
    "#testset = torchvision.datasets.MNIST(root='/content/mnist', train=False, download=True, transform=transform)\n",
    "test_content_set = ImageDataset(Path.home() / \"dataset/COCO/test2014/\", transform)\n",
    "test_content_loader = torch.utils.data.DataLoader(test_content_set,  batch_size=batch_size, shuffle=False,  num_workers=2)\n",
    "#test_style_set = torchvision.datasets.FashionMNIST(root=\"~/dataset/fashionmnist\", train=False, download=True, transform=transform)\n",
    "test_style_set = ImageDataset(Path.home() / \"dataset/AbstractGallery\", transform)\n",
    "test_style_loader = torch.utils.data.DataLoader(test_style_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "net = torch.load(os.path.join(model_output_dir, \"model_bestloss.pth\"))\n",
    "net.alpha = 0.0\n",
    "net.to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for contents, styles in zip(test_content_loader, test_style_loader):\n",
    "        contents = contents.to(device=device, dtype=torch.float32)\n",
    "        #styles = styles.to(device=device, dtype=torch.float32)\n",
    "        #outputs, _, _, _ = net(contents, styles)\n",
    "        outputs = net(encoder(contents))\n",
    "        break\n",
    "\n",
    "width = 5\n",
    "cols = 2\n",
    "fig, axes = plt.subplots(cols, batch_size, figsize=(batch_size * width, width * cols))\n",
    "for i in range(batch_size):\n",
    "    axes[0][i].imshow((contents[i].detach().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    #axes[1][i].imshow((styles[i].detach().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "    axes[1][i].imshow((outputs[i].detach().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hist(idx, bins=20):\n",
    "    content = contents[idx].detach().cpu().numpy()\n",
    "    #styles = styles[idx].detach().cpu().numpy()\n",
    "    output = outputs[idx].detach().cpu().numpy()\n",
    "    c_flatten = (content.reshape(3, -1) * 255).astype(np.uint8)\n",
    "    #s_flatten = (content.reshape(3, -1) * 255).astype(np.uint8)\n",
    "    o_flatten = (output.reshape(3, -1) * 255).astype(np.uint8)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(14, 14))\n",
    "    for i in range(3):\n",
    "        axes[i][0].hist(c_flatten[i], bins=bins)\n",
    "        #axes[i][1].hist(s_flatten[i], bins=bins)\n",
    "        axes[i][1].hist(o_flatten[i], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hist(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
